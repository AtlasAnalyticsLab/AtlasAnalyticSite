<!doctype html><html class=scroll-smooth lang=en-us dir=ltr><script>document.documentElement.classList.toggle("dark")</script><head><link rel=stylesheet href=/main.css><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><head><link rel=icon type=image/x-icon href=..//favicon.ico><link rel=stylesheet href="/css/styles.min.276770d51802f1bc692971685813979b6b4200c5d4627ef04a2a8fc7883ad470.css" integrity="sha256-J2dw1RgC8bxpKXFoWBOXm2tCAMXUYn7wSiqPx4g61HA="><title>Atlas Analytics Lab</title></head></head><body class="bg-atlas flex flex-col min-h-screen"><header class="relative z-50"><nav class="bg-atlas border-gray-200" id=header><div class="max-w-screen-xl flex flex-wrap items-start justify-start p-4 lg:p-2"><button data-collapse-toggle=navbar-default type=button class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls=navbar-default aria-expanded=false>
<span class=sr-only>Open main menu</span><svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14"><path stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 1h15M1 7h15M1 13h15"/></svg></button><div class="hidden w-full lg:block lg:w-auto" id=navbar-default><ul class="font-medium flex flex-col lg:flex-row justify-start items-start p-4 mt-4 rounded-lg bg-gray-50 lg:space-x-8 rtl:space-x-reverse lg:mt-0 lg:border-0 lg:bg-white dark:bg-atlas lg:dark:bg-atlas dark:border-gray-700"><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/>Atlas Analytics Lab</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/publications>Publications</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/team>Team</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/projects>Projects</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=https://github.com/AtlasAnalyticsLab>Software</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/news>News</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/photos>Photos</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/positions>Positions</a></li><li><a class="transition transform duration-150 block py-2 text-xs md:text-base lg:text-xl 2xl:text-2xl px-3 text-gray-900 rounded hover:bg-gray-100 lg:hover:bg-transparent lg:border-0 lg:hover:text-gray-300 lg:p-0 dark:text-white lg:dark:hover:text-gray-300 dark:hover:bg-atlas dark:hover:text-white lg:dark:hover:bg-transparent hover:scale-105" aria-current=page href=/contact>Contact</a></li></ul></div></div></nav><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js></script><script>$(document).ready(function(){$('[data-collapse-toggle="navbar-default"]').click(function(){$("#navbar-default").toggle().toggleClass("w-screen h-screen lg:w-full lg:h-full")})})</script></header><main class="relative z-30 flex-grow"><div id=canvas-container class="absolute inset-0 flex justify-center items-center z-1"></div><meta name=description content><div class="flex flex-col justify-start items-center animate-fade animate-duration-[1500ms]"><h1 class="text-6xl font-semibold text-white text-center animate-fade animate-duration-[1500ms] mt-10 mb-8">Projects</h1></div><div class="flex flex-col items-center relative z-200 mb-4 mx-8 lg:mx-0"><div class="flex flex-col lg:text-left text-center w-full lg:w-4/5 2xl:w-4/5"><p class="text-2xl lg:text-1.5xl 2xl:text-2xl font-semibold text-white col-span-full">Atlas Analytics Lab is currently addressing multiple projects in the field of deep learning and computational pathology</p></div></div><div class="flex flex-col justify-start items-center animate-fade animate-duration-[1500ms] mx-8 lg:mx-0"><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-0><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//Vasudev_Project.jpg alt="Efficient Fine-Tuning of Vision-Language Models for Multimodal Histopathology Image Analysis" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">Efficient Fine-Tuning of Vision-Language Models for Multimodal Histopathology Image Analysis</strong><p class="text-white text-lg md:text-1.5xl">Our lab is currently working on the integration of vision-language models and efficient fine-tuning algorithms on histopathology datasets, seeking to integrate multimodal information for improved medical image analysis while minimizing the consumption of high computational resources.</p></div></div></div><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-1><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//Haoyu_Project.png alt="Enhancing Model Adaptability with Test-Time Training and Meta-Learning for Robust Real-World Applications" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">Enhancing Model Adaptability with Test-Time Training and Meta-Learning for Robust Real-World Applications</strong><p class="text-white text-lg md:text-1.5xl">Our lab is researching test-time training and meta-learning to enhance model adaptability and performance in dynamic environments, allowing for rapid adjustment to new data and tasks, improving robustness in real-world applications, and facilitating continual learning and optimization across diverse scenarios.</p></div></div></div><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-2><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//Hailey_Project.jpeg alt="Streamlined Adaptation: Enhancing Computational Pathology with Parameter Efficient Fine-Tuning of Foundation Models" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">Streamlined Adaptation: Enhancing Computational Pathology with Parameter Efficient Fine-Tuning of Foundation Models</strong><p class="text-white text-lg md:text-1.5xl">Atlas Analytics Lab explores the use of parameter-efficient fine-tuning techniques on foundation models that have been pretrained on extensive datasets. By implementing these methods in computational pathology, we aim to significantly enhance model performance on new, target datasets without the need to fine-tune the entire model. This strategy seeks to optimize resource efficiency while maintaining high accuracy in diagnostic applications.</p></div></div></div><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-3><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//Cassandre_project.jpg alt="Exploring Diffusion Generative Models for Histopathology Image Synthesis and Analysis" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">Exploring Diffusion Generative Models for Histopathology Image Synthesis and Analysis</strong><p class="text-white text-lg md:text-1.5xl">Our research explores the application of Diffusion Generative Models (DGMs) for studying and synthesizing histopathology images. This work includes a comprehensive comparison of various diffusion generative methods, analyzing the characteristics they impart to the generated images. Additionally, we showcase the capability of DGMs to learn patch resolution of histopathology image patches, highlighting their utility in medical imaging applications.</p></div></div></div><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-4><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//AdaFisher.PNG alt="AdaFisher: A new adaptive second-order optimizer" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">AdaFisher: A new adaptive second-order optimizer</strong><p class="text-white text-lg md:text-1.5xl">We are currently advancing the field of optimization for deep neural networks by developing and evaluating a new adaptive second-order optimizer, AdaFisher, across a variety of tasks, including audio processing with SpeechBrain and image segmentation.</p></div></div></div><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-5><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//Cassandre_Project%282%29.jpg alt="Self-Supervised Learning for Colorectal Polyp Screening" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">Self-Supervised Learning for Colorectal Polyp Screening</strong><p class="text-white text-lg md:text-1.5xl">Our lab is advancing self-supervised learning techniques tailored for colorectal polyp screening to significantly enhance diagnostic accuracy. By strategically leveraging limited regions of interest annotations, our work aims to streamline the diagnostic workflow of pathologists, allowing for more efficient and precise identification of abnormalities.</p></div></div></div><div class="w-full lg:w-4/5 2xl:w-4/5" id=card-6><div class="grid grid-cols-11 md:grid-cols-11 lg:grid-cols-13 2xl:grid-cols-13 gap-4 bg-clip-border rounded-xl bg-gray-800 text-white shadow-md w-full mb-4 md:mb-4"><div class="col-span-3 md:col-span-3 lg:col-span-2 2xl:col-span-1 overflow-hidden rounded-r-none bg-clip-border rounded-xl h-full w-full"><div class="h-full w-full"><img src=..//Ali_Project.webp alt="Novel Architectures in Computer Vision and Self-Supervised Learning for Computational Pathology" class="object-center h-full w-full object-cover"></div></div><div class="col-span-8 md:col-span-8 lg:col-span-9 2xl:col-span-10"><strong class="block text-lg md:text-1.5xl antialiased font-bold leading-snug tracking-normal">Novel Architectures in Computer Vision and Self-Supervised Learning for Computational Pathology</strong><p class="text-white text-lg md:text-1.5xl">Our research on novel architectures for computer vision encompasses pioneering advancements in the development of innovative models and algorithms. Specifically, we focus on integrating cutting-edge self-supervised learning techniques designed for computational pathology, with the overarching goal of enhancing diagnostic precision and efficiency in the analysis of medical images.</p></div></div></div></div><footer class="absolute bottom-[-15%] left-1/2 transform -translate-x-1/2 -translate-y-1/2"><div><p class="text-white text-center text-2xs md:text-base lg:text-base xl:text-base 2xl:text-2xl font-bold">Copyright 2024. All rights reserved.</p></div><div class="bg-atlas h-8"></div><script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js integrity=sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz crossorigin=anonymous></script></footer></main></body><div id=canvas-container class="fixed flex justify-center items-center z-1"><script src=/bundle.js async></script></div></html>